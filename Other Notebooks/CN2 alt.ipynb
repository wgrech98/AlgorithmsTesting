{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>methodology</th>\n",
       "      <th>project_type</th>\n",
       "      <th>requirements_volatility</th>\n",
       "      <th>requirements_clarity</th>\n",
       "      <th>dev_time</th>\n",
       "      <th>project_size</th>\n",
       "      <th>team_size</th>\n",
       "      <th>prod_complexity</th>\n",
       "      <th>testing_intensity</th>\n",
       "      <th>risk_analysis</th>\n",
       "      <th>user_participation</th>\n",
       "      <th>team_expertise</th>\n",
       "      <th>dev_expertise</th>\n",
       "      <th>doc_needed</th>\n",
       "      <th>fund_avail</th>\n",
       "      <th>delivery_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Waterfall</td>\n",
       "      <td>System (sits between the hardware and the appl...</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>understandable/early defined</td>\n",
       "      <td>Non-Intensive</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small (1-5)</td>\n",
       "      <td>Simple</td>\n",
       "      <td>After development is done (Non-intensive testing)</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Waterfall</td>\n",
       "      <td>System (sits between the hardware and the appl...</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>understandable/early defined</td>\n",
       "      <td>Non-Intensive</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small (1-5)</td>\n",
       "      <td>Simple</td>\n",
       "      <td>After development is done (Non-intensive testing)</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Waterfall</td>\n",
       "      <td>System (sits between the hardware and the appl...</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>understandable/early defined</td>\n",
       "      <td>Non-Intensive</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small (1-5)</td>\n",
       "      <td>Simple</td>\n",
       "      <td>After development is done (Non-intensive testing)</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Waterfall</td>\n",
       "      <td>System (sits between the hardware and the appl...</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>understandable/early defined</td>\n",
       "      <td>Non-Intensive</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small (1-5)</td>\n",
       "      <td>Simple</td>\n",
       "      <td>After development is done (Non-intensive testing)</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Waterfall</td>\n",
       "      <td>System (sits between the hardware and the appl...</td>\n",
       "      <td>Fixed</td>\n",
       "      <td>understandable/early defined</td>\n",
       "      <td>Non-Intensive</td>\n",
       "      <td>Small</td>\n",
       "      <td>Small (1-5)</td>\n",
       "      <td>Simple</td>\n",
       "      <td>After development is done (Non-intensive testing)</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>Low</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    methodology                                       project_type  \\\n",
       "121   Waterfall  System (sits between the hardware and the appl...   \n",
       "122   Waterfall  System (sits between the hardware and the appl...   \n",
       "123   Waterfall  System (sits between the hardware and the appl...   \n",
       "124   Waterfall  System (sits between the hardware and the appl...   \n",
       "125   Waterfall  System (sits between the hardware and the appl...   \n",
       "\n",
       "    requirements_volatility          requirements_clarity       dev_time  \\\n",
       "121                   Fixed  understandable/early defined  Non-Intensive   \n",
       "122                   Fixed  understandable/early defined  Non-Intensive   \n",
       "123                   Fixed  understandable/early defined  Non-Intensive   \n",
       "124                   Fixed  understandable/early defined  Non-Intensive   \n",
       "125                   Fixed  understandable/early defined  Non-Intensive   \n",
       "\n",
       "    project_size    team_size prod_complexity  \\\n",
       "121        Small  Small (1-5)          Simple   \n",
       "122        Small  Small (1-5)          Simple   \n",
       "123        Small  Small (1-5)          Simple   \n",
       "124        Small  Small (1-5)          Simple   \n",
       "125        Small  Small (1-5)          Simple   \n",
       "\n",
       "                                     testing_intensity risk_analysis  \\\n",
       "121  After development is done (Non-intensive testing)          High   \n",
       "122  After development is done (Non-intensive testing)          High   \n",
       "123  After development is done (Non-intensive testing)          High   \n",
       "124  After development is done (Non-intensive testing)          High   \n",
       "125  After development is done (Non-intensive testing)          High   \n",
       "\n",
       "    user_participation team_expertise dev_expertise doc_needed fund_avail  \\\n",
       "121                Low         Medium        Medium       High        Low   \n",
       "122                Low         Medium        Medium       High        Low   \n",
       "123                Low         Medium        Medium       High        Low   \n",
       "124                Low         Medium        Medium       High        Low   \n",
       "125                Low         Medium        Medium       High        Low   \n",
       "\n",
       "    delivery_speed  \n",
       "121            Low  \n",
       "122            Low  \n",
       "123            Low  \n",
       "124            Low  \n",
       "125            Low  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import collections as clc\n",
    "import math\n",
    "from numpy.random import permutation\n",
    "\n",
    "cols = ['methodology', 'project_type', 'requirements_volatility', \n",
    "        'requirements_clarity', 'dev_time', 'project_size', 'team_size', \n",
    "        'prod_complexity', 'testing_intensity', 'risk_analysis', 'user_participation',\n",
    "        'team_expertise', 'dev_expertise', 'doc_needed', 'fund_avail', 'delivery_speed']\n",
    "        \n",
    "num_cols = [6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "\n",
    "df = pd.read_csv('SDLC1.csv', names = cols, usecols=num_cols, header = 0)\n",
    "\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b5/rpp5gn7169g6990v79kvffzc0000gp/T/ipykernel_8010/828330145.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x_train = x_train.drop('methodology',1)\n",
      "/var/folders/b5/rpp5gn7169g6990v79kvffzc0000gp/T/ipykernel_8010/828330145.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  x_test = x_test.drop('methodology',1)\n"
     ]
    }
   ],
   "source": [
    "#similar_univs = pandas.read_csv('similar_universities.csv')\n",
    "random_indices = permutation(df.index)\n",
    "test_cutoff = math.floor(len(df)/5)\n",
    "print(test_cutoff)\n",
    "test = df.loc[random_indices[1:test_cutoff]]\n",
    "train = df.loc[random_indices[test_cutoff:]]\n",
    "y_train = train['methodology']\n",
    "x_train = train\n",
    "x_train = x_train.drop('methodology',1)\n",
    "y_test = test['methodology']\n",
    "x_test = test\n",
    "x_test = x_test.drop('methodology',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CN2 Induction Algorithm\n",
    "Author: Xavier Cucurull Salamero <xavier.cucurull@estudiantat.upc.edu>\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CN2():\n",
    "    \"\"\" Implementation of the CN2 (Clark and Niblett 1989) Induction Algorithm.\n",
    "    \n",
    "    Obtain a set of ordered prediction rules from a set of examples.\n",
    "    Rules are of the form:  IF <complex> THEN predict Class\n",
    "    Definitions:\n",
    "        - Selector: a basic test on an attribute\n",
    "        - Complex: conjuction of selectors\n",
    "        - Star: group of complexes\n",
    "    \n",
    "    Example:\n",
    "        >>> cn2 = CN2()\n",
    "        >>> cn2.fit(x_train, y_train)\n",
    "        >>> y_pred = cn2.predict(x_test)\n",
    "    \"\"\"\n",
    "    def __init__(self, max_star_size=5, min_significance=0.7, verbose=0):\n",
    "        self.max_star_size = max_star_size\n",
    "        self.min_significance = min_significance\n",
    "        self.E = None\n",
    "        self.bins = {}\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def _init_selectors(self):\n",
    "        \"\"\" Initialize list of selectors by getting all the possible combinations\n",
    "        of feature-value pairs.\n",
    "        \"\"\"\n",
    "        assert self.E is not None, 'E not initialized, call self.fit(x, y) first!'\n",
    "        \n",
    "        # treat each column (except the first one - class) as features\n",
    "        for feature in self.E.columns[:0]:\n",
    "            for value in self.E[feature].unique():\n",
    "                self.selectors.append({feature: value})\n",
    "                \n",
    "    def _find_best_complex(self):\n",
    "        \"\"\" Find the best complex by iteratively specializing a star and calculating\n",
    "        the quality of its complexes.\n",
    "        \n",
    "        At each stage in the search, CN2 retains a size-limited star of 'best complexes found so far'.\n",
    "        Returns:\n",
    "            list: containing best_cpx (list of dicts), best_cpx_covered_ids (list), \n",
    "                  best_cpx_most_common_class (string) and best_cpx_precision (float)\n",
    "        \"\"\"\n",
    "        star = []\n",
    "        fist_run = True\n",
    "        best_cpx = None\n",
    "        best_cpx_covered_ids = []\n",
    "        best_cpx_most_common_class = None\n",
    "        best_cpx_precision = 0\n",
    "        best_entropy = 99\n",
    "        best_significance = 0\n",
    "        \n",
    "        # while star is not empty and significance is above min\n",
    "        # but don't keep iterating if a complex with significance 1 and entropy 0 is found\n",
    "        while len(star) and best_significance < 1 and best_significance >= self.min_significance and best_entropy > 0 or fist_run:\n",
    "            fist_run = False\n",
    "            cpx_significances = []\n",
    "            cpx_entropies = []\n",
    "            cpx_classes = []\n",
    "            \n",
    "            # specialize all complexes in star\n",
    "            new_star = self._specialize_star(star)\n",
    "            \n",
    "            # calculate entropy and significance for each complex\n",
    "            for cpx in new_star:                \n",
    "                # find covered examples\n",
    "                covered_ids = self._find_covered_examples(cpx, self.E)\n",
    "                \n",
    "                # calculate class probability distrubitions only if the complex covers examples\n",
    "                if len(covered_ids):\n",
    "                    covered_prob_dist = self.E['class'].loc[covered_ids].value_counts(sort=False, normalize=True)\n",
    "                    covered_classes = covered_prob_dist.keys()\n",
    "                    try:\n",
    "                        most_common_class = covered_prob_dist.sort_values(ascending=False).keys()[0]\n",
    "                    except:\n",
    "                        most_common_class = 'ERROR'\n",
    "                        print('ERROR - covered ex: {}'.format(covered_ids))\n",
    "                    cpx_classes.append(most_common_class)\n",
    "                    class_prob_dist = np.array(self.E['class'].loc[self.E['class'].isin(covered_classes)].value_counts(sort=False, normalize=True))     # global prob dist of covered classes\n",
    "\n",
    "                    # calculate complex entropy\n",
    "                    covered_prob_dist = np.array(covered_prob_dist)\n",
    "                    cpx_ent = entropy(covered_prob_dist)\n",
    "                        \n",
    "                    # calculate complex significance as (1 - likelihood ratio statistic)\n",
    "                    cpx_sig = 1 - np.multiply(covered_prob_dist, np.log(np.divide(covered_prob_dist, class_prob_dist))).sum() * 2\n",
    "                        \n",
    "                    # add metrics to list\n",
    "                    cpx_entropies.append(cpx_ent)\n",
    "                    cpx_significances.append(cpx_sig)\n",
    "                    \n",
    "                    # check if cpx is better than best_cpx\n",
    "                    if cpx_sig >= best_significance and cpx_ent < best_entropy:\n",
    "                        best_significance = cpx_sig\n",
    "                        best_entropy = cpx_ent\n",
    "                        best_cpx = cpx\n",
    "                        best_cpx_covered_ids = covered_ids\n",
    "                        best_cpx_most_common_class = most_common_class\n",
    "                        best_cpx_precision = np.sort(covered_prob_dist)[::-1][0]\n",
    "                else:\n",
    "                    cpx_entropies.append(99)\n",
    "                    cpx_significances.append(0)\n",
    "                    cpx_classes.append(None)\n",
    "                    \n",
    "            # create dataframe to easily sort\n",
    "            new_star_df = pd.DataFrame({'complex': new_star, 'entropy': cpx_entropies, 'significance': cpx_significances, 'class': cpx_classes})\n",
    "            # sort by complex quality (higher significance and lower entropy)\n",
    "            # and remove worst complexes from new_star to keep max_star_size\n",
    "            new_star_df = new_star_df.sort_values(by=['significance', 'entropy'], \n",
    "                                                  ascending=[False, True]).iloc[:self.max_star_size]\n",
    "            \n",
    "            star = new_star_df.complex.to_list()\n",
    "\n",
    "            # print information about each complex of the new_star\n",
    "            if self.verbose:\n",
    "                print('Len star:{}'.format(len(new_star)))\n",
    "                for i in range(len(new_star_df)):\n",
    "                    print('{} -> {} (sig: {:.3f} - ent: {:.3f})'.format(new_star_df.iloc[i, 0], new_star_df.iloc[i, 3], new_star_df.iloc[i, 2], new_star_df.iloc[i, 1]))\n",
    "                print('---------------------------------------')\n",
    "            \n",
    "        return best_cpx, best_cpx_covered_ids, best_cpx_most_common_class, best_cpx_precision\n",
    "    \n",
    "    def _specialize_star(self, star):\n",
    "        \"\"\" Specialize a star by adding new conjuctive terms to its complexes.\n",
    "        Args:\n",
    "            star (list): list of complexes\n",
    "        Returns:\n",
    "            list: new specialized star\n",
    "        \"\"\"\n",
    "        # specialize the star (subset of best complexes found so far) by adding new conjuctive terms\n",
    "        new_star = []\n",
    "        if len(star):\n",
    "            # specialize star by adding new conjuctive terms to each complex\n",
    "            for cpx in star:\n",
    "                for selector in self.selectors:\n",
    "                    sel_attribtute = list(selector)[0]\n",
    "                    if sel_attribtute not in cpx.keys():  # if attribute not in complex (avoid null)\n",
    "                        new_cpx = cpx.copy()\n",
    "                        new_cpx[sel_attribtute] = selector[sel_attribtute]  # add new selector to complex\n",
    "                        if new_cpx not in new_star:     # avoid repeating a complex (different order, but same meaning)\n",
    "                            new_star.append(new_cpx)  \n",
    "        else:\n",
    "            # initialize star with all selectors as complexes\n",
    "            new_star = [selector for selector in self.selectors]\n",
    "        \n",
    "        return new_star\n",
    "\n",
    "    def _find_covered_examples(self, cpx, df, hasclass=False):\n",
    "        \"\"\" Find all examples covered by a complex and returned\n",
    "        their corresponding indices.\n",
    "        Args:\n",
    "            cpx (dictionary): complex used as filter of the form {'attribute': value}\n",
    "            df (DataFrame): set of examples\n",
    "            hasclass (boolean): specifies if the last column of the given df is the class \n",
    "        Returns:\n",
    "            list: list of indices of the examples covered\n",
    "        \"\"\"\n",
    "        # https://stackoverflow.com/a/34162576\n",
    "        # find indices where dataframe matches filter dict\n",
    "        if hasclass:       \n",
    "            covered_ids = df.loc[(df.iloc[:, :-1][list(cpx)] == pd.Series(cpx)).all(axis=1)]\n",
    "        else:\n",
    "            covered_ids = df.loc[(df.iloc[:, :0][list(cpx)] == pd.Series(cpx)).all(axis=1)]\n",
    "        \n",
    "        return covered_ids.index\n",
    "    \n",
    "    def fit(self, X, y, n_bins=4, fixed_bin_size=False):\n",
    "        \"\"\" Fit training data and compute CN2 induction rules.\n",
    "            \n",
    "        Args:\n",
    "            x (DataFrame): training data features\n",
    "            y (array-like): training data classification\n",
    "            n_bins (int, optional): number of bins used for discretization of continuous attributes. Defaults to 4.\n",
    "            fixed_bin_size (boolean, optional): use a fixed size bin when discretizing. \n",
    "                                                True uses pandas.cut, False uses pandas.qcut Defaults to False.\n",
    "        \"\"\"\n",
    "        self.E = X.copy()\n",
    "        \n",
    "        # Discretize continuous attributes\n",
    "        for c in self.E.columns:\n",
    "            if len(self.E[c].value_counts()) > n_bins:\n",
    "                if 'int' in str(self.E[c].dtype):\n",
    "                    precision = 0\n",
    "                    if fixed_bin_size:\n",
    "                        self.E[c], self.bins[c] = pd.cut(self.E[c], n_bins, precision=precision, retbins=True, duplicates='drop')\n",
    "                    else:\n",
    "                        self.E[c], self.bins[c] = pd.qcut(self.E[c], n_bins, precision=precision, retbins=True, duplicates='drop')\n",
    "\n",
    "                elif 'float' in str(self.E[c].dtype):\n",
    "                    precision = 2\n",
    "                    if fixed_bin_size:\n",
    "                        self.E[c], self.bins[c] = pd.cut(self.E[c], n_bins, precision=precision, retbins=True, duplicates='drop')\n",
    "                    else:\n",
    "                        self.E[c], self.bins[c] = pd.qcut(self.E[c], n_bins, precision=precision, retbins=True, duplicates='drop')\n",
    "        self.E['class'] = y     # add class columns to examples DataFrame\n",
    "\n",
    "        self.selectors = []     # list of all possible selectors\n",
    "        self._init_selectors()\n",
    "        \n",
    "        # some class statistics, used later to calculate rule coverage\n",
    "        total_class_counts = pd.Series(y).value_counts()\n",
    "        \n",
    "        # get global most common class, used by default rule\n",
    "        default_class = total_class_counts.keys()[0]\n",
    "        \n",
    "        self.rules_list = []\n",
    "            \n",
    "        # loop until all examples are covered\n",
    "        while len(self.E):\n",
    "            # print examples not covered yet\n",
    "            if self.verbose:\n",
    "                print('Examples to cover:\\n {}\\n\\nCandidate complexes:\\n'.format(self.E))\n",
    "\n",
    "            # find best complex\n",
    "            best_cpx, best_cpx_covered_ids, best_cpx_most_common_class, best_cpx_precision = self._find_best_complex()\n",
    "            \n",
    "            # if best_complex not null\n",
    "            if best_cpx is not None:\n",
    "                # calculate rule coverage\n",
    "                best_cpx_coverage = self.E['class'].loc[best_cpx_covered_ids].value_counts().iloc[0] / total_class_counts[best_cpx_most_common_class]\n",
    "                                \n",
    "                # remove best_cpx_covered_ids from self.E\n",
    "                self.E.drop(best_cpx_covered_ids, inplace=True)\n",
    "\n",
    "                # add (complex, class, coverage, precision) to rules list\n",
    "                self.rules_list.append((best_cpx, best_cpx_most_common_class, best_cpx_coverage, best_cpx_precision))\n",
    "                \n",
    "                # print obtained rule\n",
    "                if self.verbose:\n",
    "                    print('Chosen rule:\\nIF {} THEN {}  [{:.2f} {:.2f}]\\n'.format(best_cpx, best_cpx_most_common_class, \n",
    "                                                                                  best_cpx_coverage, best_cpx_precision))\n",
    "        \n",
    "        # add default rule\n",
    "        self.rules_list.append((None, default_class, 0, 0))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" Use the obtained induction rules to make a prediciton on the given data.\n",
    "        Args:\n",
    "            X (DataFrame): test data features with the same header used during training (fit)\n",
    "            \n",
    "        Returns:\n",
    "            array-like: list of predictions\n",
    "        \"\"\"\n",
    "        x = X.copy()\n",
    "        y = pd.Series([None]*len(x))\n",
    "        \n",
    "        # discretize attributes using saved bins\n",
    "        for c in x.columns:\n",
    "            if c in self.bins.keys():\n",
    "                x[c] = pd.cut(x[c], self.bins[c])\n",
    "\n",
    "        assert len(self.rules_list), 'CN2 rules not induced, call self.fit(x, y) first!'\n",
    "        \n",
    "        # apply all rules in order\n",
    "        for i in range(len(self.rules_list) - 1):\n",
    "            cpx = self.rules_list[i][0]\n",
    "            prediction = self.rules_list[i][1]\n",
    "            \n",
    "            # use complex from rule and use as filter\n",
    "            covered_ids = self._find_covered_examples(cpx, x, hasclass=False)\n",
    "            \n",
    "            # update prediction Series with prediction of current rule\n",
    "            y.loc[covered_ids] = prediction            \n",
    "            \n",
    "            # remove covered examples from x DataFrame\n",
    "            x.drop(covered_ids, inplace=True)\n",
    "\n",
    "        # apply default rule to examples not classified\n",
    "        y.loc[x.index] = self.rules_list[-1][1]\n",
    "        \n",
    "        return np.array(y)\n",
    "    \n",
    "    def _generate_interpretable_rules(self):\n",
    "        \"\"\" Generate a list of rules in an interpretable way.\n",
    "        Rules are generated in the form of: IF <complex> THEN CLASS IS <class>\n",
    "        \n",
    "        This method is used by print_rules and generate_rules_table.\n",
    "        \n",
    "        Returns:\n",
    "            list: a list of strings containing the interpretable rules\n",
    "        \"\"\"\n",
    "        interpretable_rules = []\n",
    "\n",
    "        for i in range(len(self.rules_list) - 1):\n",
    "            cpx = self.rules_list[i][0]\n",
    "            prediction = self.rules_list[i][1]\n",
    "            if len(cpx) == 1:\n",
    "                rule_str = 'IF {} IS {} THEN CLASS IS {}'.format(list(cpx.keys())[0], list(cpx.values())[0], prediction)\n",
    "            else:\n",
    "                conditions = ''\n",
    "                for f, v in cpx.items():\n",
    "                    conditions += ' {} IS {} AND'.format(f, v)\n",
    "                conditions = conditions[:-4]    # remove final AND\n",
    "                \n",
    "                rule_str = 'IF{} THEN CLASS IS {}'.format(conditions, prediction)\n",
    "                \n",
    "            # add interpretable rule to list\n",
    "            interpretable_rules.append(rule_str)\n",
    "\n",
    "        # add default rule\n",
    "        interpretable_rules.append('DEFAULT CLASS IS {}'.format(self.rules_list[-1][1]))\n",
    "        \n",
    "        return interpretable_rules\n",
    "    \n",
    "    def print_rules(self):\n",
    "        \"\"\" Print all rules in an interpretable way.\n",
    "        Rules are printed in the form of: IF <complex> THEN CLASS IS <class>\n",
    "        \"\"\"\n",
    "        interpretable_rules = self._generate_interpretable_rules()\n",
    "        for r in interpretable_rules:\n",
    "            print(r)\n",
    "\n",
    "    def save_rules(self, filename):\n",
    "        \"\"\" Save the generated rules into a text file in an interpretable way\n",
    "        Args:\n",
    "            filename (str): full filename of the file where to write the rules\n",
    "        \"\"\"\n",
    "        with open(filename, 'w') as f:\n",
    "            interpretable_rules = self._generate_interpretable_rules()\n",
    "            f.write('\\n'.join(interpretable_rules) + '\\n')\n",
    "\n",
    "    def generate_rules_table(self):\n",
    "        \"\"\" Generate a table containing the interpretable rules and their corresponding coverage and precision.\n",
    "        \n",
    "        The generated pandas DataFrame can then be saved to LaTeX.\n",
    "        Returns:\n",
    "            DataFrame: table containing rules, coverage and precision\n",
    "        \"\"\"\n",
    "        interpretable_rules = self._generate_interpretable_rules()\n",
    "        rules_coverage = ['{:.2f}'.format(i[2]*100) for i in self.rules_list]\n",
    "        rules_precision = ['{:.2f}'.format(i[3]*100) for i in self.rules_list]\n",
    "        \n",
    "        rules_table = pd.DataFrame({'Rules': interpretable_rules, 'Coverage': rules_coverage, \n",
    "                                    'Precision': rules_precision})\n",
    "\n",
    "        return rules_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b5/rpp5gn7169g6990v79kvffzc0000gp/T/ipykernel_8010/3485867862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/b5/rpp5gn7169g6990v79kvffzc0000gp/T/ipykernel_8010/365249786.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_bins, fixed_bin_size)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m# find best complex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mbest_cpx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_cpx_covered_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_cpx_most_common_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_cpx_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_best_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;31m# if best_complex not null\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/b5/rpp5gn7169g6990v79kvffzc0000gp/T/ipykernel_8010/365249786.py\u001b[0m in \u001b[0;36m_find_best_complex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# sort by complex quality (higher significance and lower entropy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# and remove worst complexes from new_star to keep max_star_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             new_star_df = new_star_df.sort_values(by=['significance', 'entropy'], \n\u001b[0m\u001b[1;32m    119\u001b[0m                                                   ascending=[False, True]).iloc[:self.max_star_size]\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6242\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6244\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6242\u001b[0;31m             \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6244\u001b[0m             \u001b[0;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_label_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3425\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3427\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3429\u001b[0m         \u001b[0;31m# Do we have a slicer (on rows)?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3884\u001b[0m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3885\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3886\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_box_col_values\u001b[0;34m(self, values, loc)\u001b[0m\n\u001b[1;32m   3866\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3867\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3868\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3870\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    445\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleArrayManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, copy, attrs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_attrs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_flags\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/flags.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, allows_duplicate_labels)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0m_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"allows_duplicate_labels\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allows_duplicate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallows_duplicate_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cn2 = CN2()\n",
    "cn2.fit(x_train, y_train)\n",
    "y_pred = cn2.predict(x_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
