{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import neighbors, datasets\n",
    "from numpy.random import permutation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cols = ['methodology', 'project_type', 'requirements_volatility', \n",
    "        'requirements_clarity', 'dev_time', 'project_size', 'team_size', \n",
    "        'prod_complexity', 'testing_intensity', 'risk_analysis', 'user_participation',\n",
    "        'team_expertise', 'dev_expertise', 'doc_needed', 'fund_avail', 'delivery_speed']\n",
    "        \n",
    "num_cols = [6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "\n",
    "df = pd.read_csv('SDLC.csv', names = cols, usecols=num_cols, header = 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['risk_analysis'] = df['risk_analysis'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['user_participation'] = df['user_participation'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['team_expertise'] = df['team_expertise'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['dev_expertise'] = df['dev_expertise'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['doc_needed'] = df['doc_needed'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['fund_avail'] = df['fund_avail'].map(dict(Low=0, Medium=1,High=2))\n",
    "df['delivery_speed'] = df['delivery_speed'].map(dict(Low=0, Medium=1,High=2))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_type = {'Application (everything else)': 0,'System (sits between the hardware and the application software e.g. OSs)': 1,\n",
    "                 'Utility (performs specific tasks to keep the computer running e.g. antivirus)':2}\n",
    "requirements_volatility = {'Changing': 0,'Fixed': 1}\n",
    "requirements_clarity = {'unknown/defined later in the lifecycle': 0,'understandable/early defined': 1,}\n",
    "dev_time = {'Intensive':0, 'Non-Intensive':1}\n",
    "project_size = {'Small':0 , 'Medium':1, 'Large':2}\n",
    "team_size = {'Small (1-5)':0, 'Medium (6-15)':1, 'Large (16....)':2}\n",
    "prod_complexity = {'Simple':0, 'Complex':1}\n",
    "testing_intensity = {'After each cycle (Intensive testing)':0, 'After development is done (Non-intensive testing)':1}\n",
    "\n",
    "\n",
    "df.project_type = [project_type[item] for item in df.project_type]\n",
    "df.requirements_volatility = [requirements_volatility[item] for item in df.requirements_volatility]\n",
    "df.requirements_clarity = [requirements_clarity[item] for item in df.requirements_clarity]\n",
    "df.dev_time = [dev_time[item] for item in df.dev_time]\n",
    "df.project_size = [project_size[item] for item in df.project_size]\n",
    "df.team_size = [team_size[item] for item in df.team_size]\n",
    "df.prod_complexity = [prod_complexity[item] for item in df.prod_complexity]\n",
    "df.testing_intensity = [testing_intensity[item] for item in df.testing_intensity]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('methodology',axis=1)\n",
    "y = df[['methodology']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "# def SVM_classifier(train_input_data,train_output_data,test_input_data,test_output_data):\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "predicted_output = clf.predict(X_test)\n",
    "error_list = []\n",
    "predicted_output = predicted_output.tolist()\n",
    "test_output_data  = y_test.values.tolist()\n",
    "for i in range(len(test_output_data)):\n",
    "    cur_sdlc_similarities =  df[df['methodology'] == predicted_output[i]]\n",
    "    cur_sdlc_similarity_list = cur_sdlc_similarities.values.tolist()\n",
    "    cur_sdlc_similarity_list = [item for sublist in cur_sdlc_similarity_list for item in sublist]\n",
    "    if test_output_data[i] in cur_sdlc_similarity_list[1:]:\n",
    "        error_list.append(0)\n",
    "    else:\n",
    "        error_list.append(1)\n",
    "predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbour_list = []\n",
    "accuracy_percent = []\n",
    "for neighbours in range(1,101,5):\n",
    "    clf = neighbors.KNeighborsClassifier(neighbours, weights='uniform')\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted_output = clf.predict(X_test)\n",
    "    if isinstance(predicted_output,list) ==False:\n",
    "        predicted_output = predicted_output.tolist()\n",
    "    if isinstance(test_output_data,list) ==False:\n",
    "        test_output_data = y_test.values.tolist()\n",
    "    error_list = []\n",
    "    for i in range(len(test_output_data)):\n",
    "        cur_sdlc_similarities =  df[df['methodology'] == predicted_output[i]]\n",
    "        cur_sdlc_similarity_list = cur_sdlc_similarities.values.tolist()\n",
    "        cur_sdlc_similarity_list = [item for sublist in cur_sdlc_similarity_list for item in sublist]\n",
    "        if test_output_data[i] in cur_sdlc_similarity_list[1:]:\n",
    "            error_list.append(0)\n",
    "        else:\n",
    "            error_list.append(1)\n",
    "    neighbour_list.append(neighbours)\n",
    "    accuracy_percent.append(100 -((sum(error_list)/float(len(error_list))) * 100))\n",
    "neighbour_list = np.array(neighbour_list)\n",
    "accuracy_percent = np.array(accuracy_percent)\n",
    "plt.plot(neighbour_list,accuracy_percent)\n",
    "plt.xlabel('Number of nearest neighbors')\n",
    "plt.ylabel('Percent of accuracy')\n",
    "plt.title('Varation of accuracy with nearest neighbours')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"knn1.png\")\n",
    "plt.show()\n",
    "predicted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_classifier(train_input_data,train_output_data,test_input_data,test_output_data):\n",
    "    tree_list = []\n",
    "    accuracy_percent = []\n",
    "    for trees in range(10,200,10):\n",
    "        clf = RandomForestClassifier(trees)\n",
    "        clf.fit(train_input_data,train_output_data)\n",
    "        predicted_output = clf.predict(test_input_data)\n",
    "        error_list = []\n",
    "        if isinstance(predicted_output,list) ==False:\n",
    "            predicted_output = predicted_output.tolist()\n",
    "        if isinstance(test_output_data,list) ==False:\n",
    "            test_output_data = test_output_data.tolist()\n",
    "        for i in range(len(test_output_data)):\n",
    "            cur_univ_similarities =  similar_univs[similar_univs['univName'] == predicted_output[i]]\n",
    "            cur_univ_similarity_list = cur_univ_similarities.values.tolist()\n",
    "                cur_univ_similarity_list = [item for sublist in cur_univ_similarity_list for item in sublist]\n",
    "            if test_output_data[i] in cur_univ_similarity_list[1:]:\n",
    "                error_list.append(0)\n",
    "            else:\n",
    "                error_list.append(1)\n",
    "        tree_list.append(trees)\n",
    "        accuracy_percent.append(100 -((sum(error_list)/float(len(error_list))) * 100))\n",
    "        tree_list = np.array(tree_list)\n",
    "        accuracy_percent = np.array(accuracy_percent)\n",
    "        plt.plot(tree_list,accuracy_percent)\n",
    "        plt.xlabel('Number of trees')\n",
    "        plt.ylabel('Percent of accuracy')\n",
    "        plt.title('Varation of accuracy with trees')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"rf1.png\")\n",
    "        plt.show()\n",
    "        return predicted_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "PMMname = df['PMMname']\n",
    "characteristics = df['characteristics']\n",
    "PMM = 'Kanban'\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'title': PMMname, 'characteristics': characteristics})\n",
    "df = df[['title', 'characteristics']]\n",
    "\n",
    "# initialize the new column to hold found keywords\n",
    "df['Key_words'] = \"\"\n",
    "\n",
    "# loop the dataframe created\n",
    "for index, row in df.iterrows():\n",
    "    # initialize vectorizer for NLP\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # extracting the words by passing the text\n",
    "    vectorizer.fit_transform(row)\n",
    "\n",
    "    # getting the dictionary with key words as keys and their scores as values\n",
    "    key_words_dict_scores = vectorizer.get_feature_names()\n",
    "\n",
    "    # assigning the key words to the new column for the corresponding movie\n",
    "    row['Key_words'] = list(key_words_dict_scores)\n",
    "\n",
    "# instantiating and generating the count matrix\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(df['Key_words'].astype('str'))\n",
    "\n",
    "# generating the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "# gettin the index of the activity that matches the title\n",
    "idx = df.index[df['title'] == PMM].tolist()[0]\n",
    "\n",
    "# creating a Series with the similarity scores in descending order\n",
    "score_series = pd.Series(cosine_sim[idx]).sort_values(ascending=False)\n",
    "\n",
    "# getting the indexes of the 5 most similar activities\n",
    "top_3_indexes = list(score_series.iloc[1:4].index)\n",
    "\n",
    "# initializing the empty list to hold the recommendations\n",
    "recommended_activities = list()\n",
    "for i in top_3_indexes:\n",
    "    recommended_activities.append((df['title'].loc[i]))\n",
    "\n",
    "# now remove the original activity to not recommend it back to the user\n",
    "# fix here\n",
    "if recommended_activities.__contains__(PMM):\n",
    "    recommended_activities.remove(PMM)\n",
    "\n",
    "# append recommendations with comma\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
